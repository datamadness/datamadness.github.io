<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>TensorFlow Estimators API - Feeding large datasets from drive via TFRecords (MNIST example)</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="Exploring the world through data analysis and machine learning" />
    <link rel="shortcut icon" href="/assets/images/favicon.png" type="image/png" />
    <link rel="canonical" href="/tensorflow_estimator_large_dataset_feed" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="DATAmadness" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="TensorFlow Estimators API - Feeding large datasets from drive via TFRecords (MNIST example)" />
    <meta property="og:description" content="It is easy to hit resource limits when working with large datasets. In particular, the available memory becomes quickly a limiting factor when training your neural networks on swaths of data. The solution is to create a continuous stream of data that will sequentially read batch data from drive(s). Using" />
    <meta property="og:url" content="/tensorflow_estimator_large_dataset_feed" />
    <meta property="og:image" content="/assets/images/tf_file_feed/infographic-design-banner.jpg" />
    <meta property="article:publisher" content="https://www.facebook.com/ghost" />
    <meta property="article:author" content="https://www.facebook.com/ghost" />
    <meta property="article:published_time" content="2019-03-23T03:35:00-07:00" />
    <meta property="article:modified_time" content="2019-03-23T03:35:00-07:00" />
    <meta property="article:tag" content="Python" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="TensorFlow Estimators API - Feeding large datasets from drive via TFRecords (MNIST example)" />
    <meta name="twitter:description" content="It is easy to hit resource limits when working with large datasets. In particular, the available memory becomes quickly a limiting factor when training your neural networks on swaths of data. The solution is to create a continuous stream of data that will sequentially read batch data from drive(s). Using" />
    <meta name="twitter:url" content="/" />
    <meta name="twitter:image" content="/assets/images/tf_file_feed/infographic-design-banner.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="DATAmadness" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Python" />
    <meta name="twitter:site" content="@Mr_Bubble_Wrap" />
    <meta name="twitter:creator" content="@Mr_Bubble_Wrap" />
    <meta property="og:image:width" content="1400" />
    <meta property="og:image:height" content="933" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "DATAmadness",
        "logo": "/assets/images/blog-icon.png"
    },
    "url": "/tensorflow_estimator_large_dataset_feed",
    "image": {
        "@type": "ImageObject",
        "url": "/assets/images/tf_file_feed/infographic-design-banner.jpg",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "/tensorflow_estimator_large_dataset_feed"
    },
    "description": "It is easy to hit resource limits when working with large datasets. In particular, the available memory becomes quickly a limiting factor when training your neural networks on swaths of data. The solution is to create a continuous stream of data that will sequentially read batch data from drive(s). Using"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="TensorFlow Estimators API - Feeding large datasets from drive via TFRecords (MNIST example)" href="/feed.xml" />


</head>
<body class="post-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->

<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="/"><img src="/assets/images/blog-icon.png" alt="DATAmadness" /></a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-Statistics" role="menuitem"><a href="/tag/statistics/">Statistics</a></li>
    <li class="nav-Python" role="menuitem"><a href="/tag/python/">Python</a></li>
</ul>

        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
                <a class="social-link social-link-fb" href="https://facebook.com/ghost" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>
</a>
            
            
                <a class="social-link social-link-tw" href="https://twitter.com/Mr_Bubble_Wrap" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>
</a>
            
        </div>
        
    </div>
</nav>

		
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
>
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://vincenttam.github.io/javascripts/MathJaxLocal.js"
>
</script>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full post tag-Python ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime="23 March 2019">23 March 2019</time>
                    
                        <span class="date-divider">/</span>
                        
                            
                               <a href='/tag/python/'>PYTHON</a>
                            
                        
                    
                </section>
                <h1 class="post-full-title">TensorFlow Estimators API - Feeding large datasets from drive via TFRecords (MNIST example)</h1>
            </header>

            
            <figure class="post-full-image" style="background-image: url(/assets/images/tf_file_feed/infographic-design-banner.jpg)">
            </figure>
            

            <section class="post-full-content">
                <div class="kg-card-markdown">
                    <p>It is easy to hit resource limits when working with large datasets. In particular, the available memory becomes quickly a limiting factor when training your neural networks on swaths of data. The solution is to create a continuous stream of data that will sequentially read batch data from drive(s). Using this approach, the memory needs to hold only one batch of data while pre-loading the data for the next batch, allowing us to operate with datasets of virtually unlimited size.</p>

<p>This article demonstrates the approach on the popular <a href="http://yann.lecun.com/exdb/mnist/">MNIST dataset</a> using TensorFlow Estimators API, TFRecords and Data API.</p>

<p>You can get the full python example from <a href="https://github.com/datamadness/Feeding-TensorFlow-from-drive-MNIST-Example">my GitHub repo</a>. Specifically, youâ€™ll find these two python files:</p>

<p><code class="highlighter-rouge">MNIST2TFRfilesDataAPI.py</code><br />
<code class="highlighter-rouge">MNIST_CNN_with_TFR_iterator_example.py</code></p>

<h4 id="high-level-workflow-overview">High Level Workflow Overview</h4>
<ol>
  <li>Load MNIST dataset via Keras</li>
  <li>Serialize the data into list(s)</li>
  <li>Save the data on drive in TFRecord format</li>
  <li>Create Estimator API input function that builds dataset from TFRecords using an iterator</li>
  <li>Train Convolutional Neural Network streaming the data via a custom input function</li>
</ol>

<h4 id="saving-data-in-tfrecord-format">Saving Data in TFRecord format</h4>
<p>The MNIST training dataset consists of 60000 28x28 images of hand written digits such as this one:
<img src="/assets/images/tf_file_feed/MNIST_digit.png" alt="image post" /></p>

<p>To save this data into TFRecord format, couple of things needs to happen:</p>

<ul>
  <li>The data must be represented in dictionary format</li>
  <li>Individual dictionary values should be flattened into scalars or 1D arrays suitable for storing as series</li>
</ul>

<p>The following function tranforms a single 28x28 MNIST digit into the desired format. Notice that the dictionary can have an arbitrary number of keys which is useful for storing any metadata such as original data dimension or training labels:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_observation</span><span class="p">(</span><span class="n">observation_id</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">img_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">observation_id</span><span class="p">,:,:]</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">img_data</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">observation_data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">'height'</span><span class="p">:</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="s">'width'</span><span class="p">:</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="c">#Flatten 2D array into 1D arrye so it can be stored as a list</span>
            <span class="s">'img_string'</span><span class="p">:</span> <span class="n">img_data</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="s">'C'</span><span class="p">),</span>
            <span class="s">'label'</span><span class="p">:</span> <span class="n">train_labels</span><span class="p">[</span><span class="n">observation_id</span><span class="p">]</span>
            <span class="p">}</span>
    <span class="k">return</span> <span class="n">observation_data</span>
</code></pre></div></div>

<p>The next step in generating the TFRecords is to transform the dictionary into an object where all values from the dictionary are saved into one of the three TensorFlow datatype lists:</p>

<ul>
  <li>Int64List</li>
  <li>FloatList</li>
  <li>ByteList</li>
</ul>

<p>Each datatype can offer different advantages, so it is worth experimenting with them. For example, I was able to significantly reduce the size required for storing the files by encoding Floats/Integers into ByteList, but it increases complexity of your code and it benefits only certain data structures.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_example_object</span><span class="p">(</span><span class="n">single_record</span><span class="p">):</span>
    
    <span class="n">record</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Example</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Features</span><span class="p">(</span><span class="n">feature</span><span class="o">=</span><span class="p">{</span>
        <span class="s">'height'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Feature</span><span class="p">(</span>
            <span class="n">int64_list</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Int64List</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="n">single_record</span><span class="p">[</span><span class="s">'height'</span><span class="p">]])),</span>
        <span class="s">'width'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Feature</span><span class="p">(</span>
            <span class="n">int64_list</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Int64List</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="n">single_record</span><span class="p">[</span><span class="s">'width'</span><span class="p">]])),</span>
        <span class="s">'img_string'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Feature</span><span class="p">(</span>
            <span class="n">float_list</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">FloatList</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="n">single_record</span><span class="p">[</span><span class="s">'img_string'</span><span class="p">])),</span> 
            <span class="c">#bytes_list=tf.train.BytesList(value=[single_record['img_string'].tobytes(order='C')])), </span>
        <span class="s">'label'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Feature</span><span class="p">(</span>
            <span class="n">int64_list</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Int64List</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="p">[</span><span class="n">single_record</span><span class="p">[</span><span class="s">'label'</span><span class="p">]]))</span>
    <span class="p">}))</span>
    <span class="k">return</span> <span class="n">record</span>
</code></pre></div></div>

<p>Using the transformation functions above, we can finally write the MNIST trainig dataset into TFRecord files. The following piece of code save the dataset into 10 files with 6000 records per file:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#Number of TFR files to save the data into</span>
<span class="n">numFiles</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">records_per_file</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span><span class="o">/</span><span class="n">numFiles</span><span class="p">)</span>

<span class="k">for</span> <span class="n">file_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numFiles</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">python_io</span><span class="o">.</span><span class="n">TFRecordWriter</span><span class="p">(</span><span class="s">'MNIST_train_data_strings_'</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">file_id</span><span class="p">)</span> <span class="o">+</span> <span class="s">'.tfrecord'</span><span class="p">)</span> <span class="k">as</span> <span class="n">tfwriter</span><span class="p">:</span>
        
        <span class="c"># Iterate through all records</span>
        <span class="k">for</span> <span class="n">observation_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">records_per_file</span><span class="p">):</span>
            <span class="n">observation_data</span> <span class="o">=</span> <span class="n">get_observation</span><span class="p">(</span><span class="n">observation_id</span> <span class="o">+</span> <span class="n">file_id</span> <span class="o">*</span> <span class="n">records_per_file</span><span class="p">)</span>
            <span class="n">example</span> <span class="o">=</span> <span class="n">get_example_object</span><span class="p">(</span><span class="n">observation_data</span><span class="p">)</span>
    
            <span class="c"># Append each record into TFRecord</span>
            <span class="n">tfwriter</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">example</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
</code></pre></div></div>

<h4 id="builing-an-input-function-for-estimators-api-usign-tensorflow-data-api">Builing an input function for Estimators API usign TensorFlow Data API</h4>
<p>Once we have the data saved into TFRecords on a drive, the next step is to write an input fucntion for the Estimators API that will stream the data into your model. 
The easiest way to accomplish this is via the Data API, specifically the TFRecordDataset class that will directly create a dataset from list of TFRecord files. The Estimators and Data APIs are designed to work together, so you do not even have to initialize the iterator for your dataset.
The only trick to this is that you have to write a parser that will transform the serialized data in lists back into format suitable for your model. As such this is also a perfect place to build your pipeline for further data preprocessing, transformation and feature engineering.</p>

<p>Here is the input function for our MNIST dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">dataset_input_fn</span><span class="p">(</span><span class="n">subfolder</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
         
    <span class="n">filenames</span> <span class="o">=</span> <span class="p">[</span><span class="nb">file</span> <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="n">subfolder</span><span class="p">))</span> <span class="k">if</span> <span class="nb">file</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s">'.tfrecord'</span><span class="p">)]</span>
    <span class="n">filenames</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">subfolder</span><span class="p">,</span> <span class="nb">file</span><span class="p">)</span> <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">]</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TFRecordDataset</span><span class="p">(</span><span class="n">filenames</span><span class="p">)</span>

    <span class="c">#Create record extraction function</span>
    <span class="k">def</span> <span class="nf">parser</span><span class="p">(</span><span class="n">record</span><span class="p">):</span>
        <span class="n">features</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">'height'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
            <span class="s">'width'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
            <span class="s">'img_string'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">VarLenFeature</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
            <span class="s">'label'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)}</span>
        <span class="n">parsed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">parse_single_example</span><span class="p">(</span><span class="n">record</span><span class="p">,</span> <span class="n">features</span><span class="p">)</span>
        
        <span class="c"># Perform additional preprocessing on the parsed data.</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">parsed</span><span class="p">[</span><span class="s">'img_string'</span><span class="p">]</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">to_dense</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">default_value</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">parsed</span><span class="p">[</span><span class="s">"label"</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    
        <span class="k">return</span> <span class="p">{</span><span class="s">"image_data"</span><span class="p">:</span> <span class="n">image</span><span class="p">,</span> <span class="s">"width"</span><span class="p">:</span> <span class="n">parsed</span><span class="p">[</span><span class="s">"width"</span><span class="p">]},</span> <span class="n">label</span>

    <span class="c"># Use `Dataset.map()` to build a pair of a feature dictionary and a label</span>
    <span class="c"># tensor for each example.</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    
    <span class="c">#Shuffle data if in training mode</span>
    <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">batch_size</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>
    
    <span class="c"># Each element of `dataset` is tuple containing a dictionary of features</span>
    <span class="c"># (in which each value is a batch of values for that feature), and a batch of</span>
    <span class="c"># labels.</span>
    <span class="k">return</span> <span class="n">dataset</span>
</code></pre></div></div>

<h4 id="plugging-it-all-together-training-your-cnn-on-a-data-stream-from-tfr-files">Plugging it all together: Training your CNN on a data stream from TFR files</h4>

<p>Now when we have all the bits ready, we can put it all together and train our MNIST CNN on a data streaming from TFRecord files saved on your drive. Here is the complete modified <a href="https://www.tensorflow.org/tutorials/estimators/cnn">MNIST CNN example from TensorFlow page</a>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="c">#%% Specify parameters </span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">100</span>                    <span class="c">#Note that large batch sized is linked to sharp gradients</span>
<span class="n">training_steps</span> <span class="o">=</span> <span class="mi">100</span>                <span class="c">#Number of batches to train on (100 for a quick test, 1000 or more for results)</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="bp">None</span>                   <span class="c">#None to repeat dataset until all steps are executed</span>
<span class="n">eval_folder</span> <span class="o">=</span> <span class="s">'MNIST_TFRs_eval'</span>     <span class="c">#Subfolder containing TFR files with evaluation data</span>
<span class="n">train_folder</span> <span class="o">=</span> <span class="s">'MNIST_TFRs_train'</span>   <span class="c">#Subfolder containing TFR files with training data</span>
<span class="c">#%% Building the CNN MNIST Classifier</span>
<span class="k">def</span> <span class="nf">cnn_model_fn</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
  <span class="s">"""Model function for CNN."""</span>
  <span class="n">input_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s">"image_data"</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
  
  <span class="c"># Convolutional Layer #1</span>
  <span class="n">conv1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span>
      <span class="n">inputs</span><span class="o">=</span><span class="n">input_layer</span><span class="p">,</span>
      <span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
      <span class="n">kernel_size</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
      <span class="n">padding</span><span class="o">=</span><span class="s">"same"</span><span class="p">,</span>
      <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>

  <span class="c"># Pooling Layer #1</span>
  <span class="n">pool1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">max_pooling2d</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">conv1</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

  <span class="c"># Convolutional Layer #2 and Pooling Layer #2</span>
  <span class="n">conv2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span>
      <span class="n">inputs</span><span class="o">=</span><span class="n">pool1</span><span class="p">,</span>
      <span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
      <span class="n">kernel_size</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
      <span class="n">padding</span><span class="o">=</span><span class="s">"same"</span><span class="p">,</span>
      <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>
  <span class="n">pool2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">max_pooling2d</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">conv2</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

  <span class="c"># Dense Layer</span>
  <span class="n">pool2_flat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">pool2</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">64</span><span class="p">])</span>
  <span class="n">dense</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">pool2_flat</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span> 
  <span class="n">dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span>
      <span class="n">inputs</span><span class="o">=</span><span class="n">dense</span><span class="p">,</span> <span class="n">rate</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">mode</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">)</span>

  <span class="c"># Logits Layer</span>
  <span class="n">logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span> <span class="n">units</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

  <span class="n">predictions</span> <span class="o">=</span> <span class="p">{</span>
      <span class="c"># Generate predictions (for PREDICT and EVAL mode)</span>
      <span class="s">"classes"</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="nb">input</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
      <span class="c"># Add `softmax_tensor` to the graph. It is used for PREDICT and by the</span>
      <span class="c"># `logging_hook`.</span>
      <span class="s">"probabilities"</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"softmax_tensor"</span><span class="p">)</span>
  <span class="p">}</span>

  <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">EstimatorSpec</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">)</span>

  <span class="c"># Calculate Loss (for both TRAIN and EVAL modes)</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">sparse_softmax_cross_entropy</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>

  <span class="c"># Configure the Training Op (for TRAIN mode)</span>
  <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
    <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span>
        <span class="n">global_step</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">get_global_step</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">EstimatorSpec</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">train_op</span><span class="o">=</span><span class="n">train_op</span><span class="p">)</span>

  <span class="c"># Add evaluation metrics (for EVAL mode)</span>
  <span class="n">eval_metric_ops</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s">"accuracy"</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span>
          <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">[</span><span class="s">"classes"</span><span class="p">])</span>
  <span class="p">}</span>
  <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">EstimatorSpec</span><span class="p">(</span>
      <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">eval_metric_ops</span><span class="o">=</span><span class="n">eval_metric_ops</span><span class="p">)</span>

<span class="c">#%% CREATE ESTIMATOR</span>

<span class="c"># Create the Estimator</span>
<span class="n">mnist_classifier</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">estimator</span><span class="o">.</span><span class="n">Estimator</span><span class="p">(</span>
    <span class="n">model_fn</span><span class="o">=</span><span class="n">cnn_model_fn</span><span class="p">,</span> <span class="n">model_dir</span><span class="o">=</span><span class="s">"/tmp2/mnist_convnet_model"</span><span class="p">)</span>

<span class="c">#%% Set Up a Logging Hook</span>

<span class="c"># Set up logging for predictions</span>
<span class="n">tensors_to_log</span> <span class="o">=</span> <span class="p">{</span><span class="s">"probabilities"</span><span class="p">:</span> <span class="s">"softmax_tensor"</span><span class="p">}</span>

<span class="n">logging_hook</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">LoggingTensorHook</span><span class="p">(</span>
    <span class="n">tensors</span><span class="o">=</span><span class="n">tensors_to_log</span><span class="p">,</span> <span class="n">every_n_iter</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="c">#%% Input function for training data</span>

<span class="k">def</span> <span class="nf">dataset_input_fn</span><span class="p">(</span><span class="n">subfolder</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
         
    <span class="n">filenames</span> <span class="o">=</span> <span class="p">[</span><span class="nb">file</span> <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> 
		<span class="n">subfolder</span><span class="p">))</span> <span class="k">if</span> <span class="nb">file</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s">'.tfrecord'</span><span class="p">)]</span>
    <span class="n">filenames</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">subfolder</span><span class="p">,</span> <span class="nb">file</span><span class="p">)</span> <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">filenames</span><span class="p">]</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">TFRecordDataset</span><span class="p">(</span><span class="n">filenames</span><span class="p">)</span>

    <span class="c">#Create record extraction function</span>
    <span class="k">def</span> <span class="nf">parser</span><span class="p">(</span><span class="n">record</span><span class="p">):</span>
        <span class="n">features</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">'height'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
            <span class="s">'width'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
            <span class="s">'img_string'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">VarLenFeature</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
            <span class="s">'label'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">FixedLenFeature</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">)}</span>
        <span class="n">parsed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">parse_single_example</span><span class="p">(</span><span class="n">record</span><span class="p">,</span> <span class="n">features</span><span class="p">)</span>
        
        <span class="c"># Perform additional preprocessing on the parsed data.</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">parsed</span><span class="p">[</span><span class="s">'img_string'</span><span class="p">]</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">to_dense</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">default_value</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">parsed</span><span class="p">[</span><span class="s">"label"</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    
        <span class="k">return</span> <span class="p">{</span><span class="s">"image_data"</span><span class="p">:</span> <span class="n">image</span><span class="p">,</span> <span class="s">"width"</span><span class="p">:</span> <span class="n">parsed</span><span class="p">[</span><span class="s">"width"</span><span class="p">]},</span> <span class="n">label</span>

    <span class="c"># Use `Dataset.map()` to build a pair of a feature dictionary and a label</span>
    <span class="c"># tensor for each example.</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span>
    
    <span class="c">#Shuffle data if in training mode</span>
    <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">batch_size</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>
    
    <span class="c"># Each element of `dataset` is tuple containing a dictionary of features</span>
    <span class="c"># (in which each value is a batch of values for that feature), and a batch of</span>
    <span class="c"># labels.</span>
    <span class="k">return</span> <span class="n">dataset</span>

<span class="c">#%% Playground for understanding the dataset workflow / experimenting - not for actual CNN</span>
<span class="c">#sess = tf.InteractiveSession()</span>
<span class="c">#dataset = dataset_input_fn(train_folder, train = True, batch_size = 1, num_epochs=None)</span>
<span class="c">#iterator = dataset.make_one_shot_iterator()</span>
<span class="c">#batch = iterator.get_next()</span>
<span class="c">#image_tensor = tf.reshape(d[0]["image_data"], [-1, 28, 28])</span>
<span class="c">#image = image_tensor.eval()</span>
<span class="c">#%% Train the clasifier</span>
<span class="n">mnist_classifier</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">input_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="p">:</span> <span class="n">dataset_input_fn</span><span class="p">(</span><span class="n">train_folder</span><span class="p">,</span> <span class="n">train</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">),</span>
    <span class="c">#input_fn=dataset_train_input_fn,</span>
    <span class="n">steps</span><span class="o">=</span><span class="n">training_steps</span><span class="p">,</span>
    <span class="n">hooks</span><span class="o">=</span><span class="p">[</span><span class="n">logging_hook</span><span class="p">])</span>
<span class="c">#%% Evaluate the model</span>
<span class="n">eval_results</span> <span class="o">=</span> <span class="n">mnist_classifier</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span>
        <span class="n">input_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="p">:</span> <span class="n">dataset_input_fn</span><span class="p">(</span><span class="n">eval_folder</span><span class="p">,</span> <span class="n">train</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span>
			<span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="c">#input_fn=dataset_eval_input_fn)</span>
<span class="k">print</span><span class="p">(</span><span class="n">eval_results</span><span class="p">)</span>

</code></pre></div></div>

                </div>
            </section>

            <!-- Email subscribe form at the bottom of the page -->
            

            <footer class="post-full-footer">
                <!-- Everything inside the #author tags pulls data from the author -->
                <!-- #author-->
                
                    
                        <section class="author-card">
                            
                                <img class="author-profile-image" src="/assets/images/DM_favicon.png" alt="DATAmadness" />
                            
                            <section class="author-card-content">
                                <h4 class="author-card-name"><a href="/author/DATAmadness">DATAmadness</a></h4>
                                
                                    <p>It is a capital mistake to theorize before one has data.â€ â€” Sherlock Holmes</p>
                                
                            </section>
                        </section>
                        <div class="post-full-footer-right">
                            <a class="author-card-button" href="/author/DATAmadness">Read More</a>
                        </div>
                    
                
                <!-- /author  -->
            </footer>

            <!-- If you use Disqus comments, just uncomment this block.
            The only thing you need to change is "test-apkdzgmqhj" - which
            should be replaced with your own Disqus site-id. -->
            

        </article>

    </div>
</main>

<!-- Links to Previous/Next posts -->
<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
                
                
                
                
                    <article class="read-next-card"
                        
                            style="background-image: url(/assets/images/blog-cover.png)"
                        
                    >
                        <header class="read-next-card-header">
                            <small class="read-next-card-header-sitetitle">&mdash; DATAmadness &mdash;</small>
                            
                                <h3 class="read-next-card-header-title"><a href="/tag/python/">Python</a></h3>
                            
                        </header>
                        <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
</div>
                        <div class="read-next-card-content">
                            <ul>
                                
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/time-signal-CNN-part2">Time series classification using Convolutional Neural Network in TensorFlow - Part 2</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/time-signal-CNN">Time series classification using Convolutional Neural Network in TensorFlow - Part 1</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/tensorflow_input_funtion_tip">TensorFlow Tip - input_fn with custom parameters</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                            </ul>
                        </div>
                        <footer class="read-next-card-footer">
                            <a href="/tag/python/">
                                
                                    See all 5 posts  â†’
                                
                            </a>
                        </footer>
                    </article>
                
            

            <!-- If there's a next post, display it using the same markup included from - partials/post-card.hbs -->
            
                
    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/tensorflow_input_funtion_tip">
                <div class="post-card-image" style="background-image: url(/assets/images/input_function/Fort_Gibson_dam_2.jpg)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/tensorflow_input_funtion_tip">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Python</span>
                            
                        
                    

                    <h2 class="post-card-title">TensorFlow Tip - input_fn with custom parameters</h2>
                </header>
                <section class="post-card-excerpt">
                    <p>TensorFlow Estimators API is great for quickly building your custom models, but you might have noticed there is no obvious way to pass custom parameters into the input_fn from your estimator. That can</p>
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                        
                        <img class="author-profile-image" src="/assets/images/DM_favicon.png" alt="DATAmadness" />
                        
                        <span class="post-card-author">
                            <a href="/author/DATAmadness/">DATAmadness</a>
                        </span>
                    
                
            </footer>
        </div>
    </article>

            

            <!-- If there's a previous post, display it using the same markup included from - partials/post-card.hbs -->
            
                
    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/Skewness_Auto_Transform">
                <div class="post-card-image" style="background-image: url(/assets/images/Skew_autotransform/header_spyder.png)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/Skewness_Auto_Transform">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Python</span>
                            
                        
                    

                    <h2 class="post-card-title">Python function to automatically transform skewed data in Pandas DataFrame</h2>
                </header>
                <section class="post-card-excerpt">
                    <p>When I stumble on an interesting new dataset, I often find myself excitedly prototyping a quick machine learning models to see what type of insights I could get out of the latest find.</p>
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                        
                        <img class="author-profile-image" src="/assets/images/DM_favicon.png" alt="DATAmadness" />
                        
                        <span class="post-card-author">
                            <a href="/author/DATAmadness/">DATAmadness</a>
                        </span>
                    
                
            </footer>
        </div>
    </article>

            

        </div>
    </div>
</aside>

<!-- Floating header which appears on-scroll, included from includes/floating-header.hbs -->
<div class="floating-header">
    <div class="floating-header-logo">
        <a href="/">
            
                <img src="/assets/images/favicon.png" alt="DATAmadness icon" />
            
            <span>DATAmadness</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">TensorFlow Estimators API - Feeding large datasets from drive via TFRecords (MNIST example)</div>
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=TensorFlow+Estimators+API+-+Feeding+large+datasets+from+drive+via+TFRecords+%28MNIST+example%29&amp;url=https://datamadness.github.io/tensorflow_estimator_large_dataset_feed"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https://datamadness.github.io/tensorflow_estimator_large_dataset_feed"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>


<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->


        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="/">DATAmadness</a> &copy; 2019</section>
                <section class="poweredby">Published with Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyller/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                <nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    <a href="https://facebook.com/ghost" target="_blank" rel="noopener">Facebook</a>
                    <a href="https://twitter.com/Mr_Bubble_Wrap" target="_blank" rel="noopener">Twitter</a>
                    <a href="https://www.nasa.gov/multimedia/nasatv#public" target="_blank" rel="noopener">Watch live stream from ISS to relax</a>
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-121059326-1', 'auto');
  ga('send', 'pageview');

 </script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
